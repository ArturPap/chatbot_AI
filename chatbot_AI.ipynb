{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKZ+q8UgTaFsrcNEgHUwW1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArturPap/chatbot_AI/blob/main/chatbot_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjPZ0CRv21Vs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "import torch\n",
        "import sqlite3\n",
        "import logging\n",
        "from typing import List, Dict, Any\n",
        "import asyncio\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class AIPoweredChatbot:\n",
        "    def __init__(self, model_name: str = \"distilgpt2\", db_path: str = \"chatbot_data.db\"):\n",
        "        \"\"\"Initialize the AI chatbot with RAG capabilities.\"\"\"\n",
        "        try:\n",
        "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(model_name).to(self.device)\n",
        "            self.embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "            self.vector_store = None\n",
        "            self.db_path = db_path\n",
        "            self._initialize_database()\n",
        "            logger.info(\"Chatbot initialized successfully\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Initialization failed: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _initialize_database(self) -> None:\n",
        "        \"\"\"Set up SQLite database for storing conversation history.\"\"\"\n",
        "        try:\n",
        "            with sqlite3.connect(self.db_path) as conn:\n",
        "                cursor = conn.cursor()\n",
        "                cursor.execute(\"\"\"\n",
        "                    CREATE TABLE IF NOT EXISTS conversations (\n",
        "                        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                        user_input TEXT,\n",
        "                        response TEXT,\n",
        "                        timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        "                    )\n",
        "                \"\"\")\n",
        "                conn.commit()\n",
        "        except sqlite3.Error as e:\n",
        "            logger.error(f\"Database initialization failed: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def load_documents(self, file_path: str) -> None:\n",
        "        \"\"\"Load and index documents for RAG.\"\"\"\n",
        "        try:\n",
        "            loader = PyPDFLoader(file_path)\n",
        "            documents = loader.load()\n",
        "            texts = [doc.page_content for doc in documents]\n",
        "            self.vector_store = FAISS.from_texts(texts, self.embeddings)\n",
        "            logger.info(f\"Loaded and indexed {len(texts)} documents\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Document loading failed: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    async def generate_response(self, user_input: str, max_length: int = 100) -> str:\n",
        "        \"\"\"Generate response using RAG and LLM.\"\"\"\n",
        "        try:\n",
        "            # Retrieve relevant context using RAG\n",
        "            if self.vector_store:\n",
        "                docs = self.vector_store.similarity_search(user_input, k=3)\n",
        "                context = \" \".join([doc.page_content for doc in docs])\n",
        "            else:\n",
        "                context = \"\"\n",
        "\n",
        "            # Prepare input for the model\n",
        "            prompt = f\"Context: {context}\\nUser: {user_input}\\nAssistant: \"\n",
        "            inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "            # Generate response\n",
        "            outputs = self.model.generate(\n",
        "                **inputs,\n",
        "                max_length=max_length,\n",
        "                num_return_sequences=1,\n",
        "                temperature=0.7,\n",
        "                top_p=0.9,\n",
        "                do_sample=True\n",
        "            )\n",
        "\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "            # Store conversation in database\n",
        "            self._store_conversation(user_input, response)\n",
        "\n",
        "            logger.info(\"Response generated successfully\")\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Response generation failed: {str(e)}\")\n",
        "            return \"An error occurred while generating the response.\"\n",
        "\n",
        "    def _store_conversation(self, user_input: str, response: str) -> None:\n",
        "        \"\"\"Store conversation in the database.\"\"\"\n",
        "        try:\n",
        "            with sqlite3.connect(self.db_path) as conn:\n",
        "                cursor = conn.cursor()\n",
        "                cursor.execute(\n",
        "                    \"INSERT INTO conversations (user_input, response) VALUES (?, ?)\",\n",
        "                    (user_input, response)\n",
        "                )\n",
        "                conn.commit()\n",
        "        except sqlite3.Error as e:\n",
        "            logger.error(f\"Failed to store conversation: {str(e)}\")\n",
        "\n",
        "    def analyze_conversation_history(self) -> pd.DataFrame:\n",
        "        \"\"\"Analyze conversation history using Pandas.\"\"\"\n",
        "        try:\n",
        "            with sqlite3.connect(self.db_path) as conn:\n",
        "                df = pd.read_sql_query(\"SELECT * FROM conversations\", conn)\n",
        "\n",
        "            # Basic analysis\n",
        "            df['response_length'] = df['response'].str.len()\n",
        "            df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "\n",
        "            logger.info(\"Conversation history analyzed\")\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Conversation analysis failed: {str(e)}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "async def main():\n",
        "    \"\"\"Main function to demonstrate chatbot usage.\"\"\"\n",
        "    chatbot = AIPoweredChatbot()\n",
        "\n",
        "    # Load sample documents (assuming a PDF file exists)\n",
        "    try:\n",
        "        chatbot.load_documents(\"sample_knowledge_base.pdf\")\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"Could not load documents: {str(e)}\")\n",
        "\n",
        "    # Example interaction\n",
        "    user_input = \"What is machine learning?\"\n",
        "    response = await chatbot.generate_response(user_input)\n",
        "    print(f\"User: {user_input}\")\n",
        "    print(f\"Assistant: {response}\")\n",
        "\n",
        "    # Analyze conversation history\n",
        "    analysis = chatbot.analyze_conversation_history()\n",
        "    print(\"\\nConversation Analysis:\")\n",
        "    print(analysis.describe())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ]
    }
  ]
}